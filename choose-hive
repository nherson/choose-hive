#!/bin/bash

read -d '' USAGE <<EOF
choose-hive:
  -u -- user to log into hive servers as (e.g. cs194-ap)
  -i -- path to private key to use
  -h -- display this help message
EOF

while getopts ":u:i:h" opt; do
  case $opt in
    u)
      HIVE_USER=$OPTARG
      ;;
    i)
      ID_FILE=$OPTARG
      ;;
    h)
      echo "$USAGE"
      exit 127
      ;;
    :)
      echo "Option -$OPTARG requires an argument."
      exit 1
      ;;
  esac
done


# SCRIPT VARIABLES

# If no user is specified, bail
[[ -z $HIVE_USER ]] && echo "No user specified. Run with -u USER" && exit 1
# If no private key path is given, choose a sane default
[[ -z $ID_FILE ]] && echo "Warning: No private key path given, defaulting to $HOME/.ssh/id_rsa" && ID_FILE=${HOME}/.ssh/id_rsa
# Location of temp file to use as a pseudo-lock
LOCK_FILE=/tmp/choose-hive.lock
# Location of pipe file for subshells to relay number of users
PIPE_FILE=/tmp/choose-hive.pipe

min_users=NONE
min_users_host=0


# SUBROUTINES

# Checks the host at the given number
# e.g. `check_host 3` checks the status of hive3
# Uses locking via mkdir to let the SSH tasks run in parallel
check_host() {
  i=$1
  if ping -W 1 -c 1 -t 2 hive$i.cs.berkeley.edu > /dev/null; then
    user_data=$(ssh -o PasswordAuthentication=no -o ConnectTimeout=2 -o StrictHostKeyChecking=no -i $ID_FILE $HIVE_USER@hive$i.cs.berkeley.edu "w -h" 2>/dev/null)
    if [[ "$?" == "0" ]]; then
      users=$(echo "$user_data" | wc -l | tr -d ' ')
      lockfile -1 $LOCK_FILE
      echo "$users:$i" > $PIPE_FILE
    else
      lockfile -1 $LOCK_FILE
      echo "-1:$i" > $PIPE_FILE
    fi
  else
    lockfile -1 $LOCK_FILE
    echo "-1:$i" > $PIPE_FILE
  fi
  rm -rf $LOCK_FILE
}

# Given an number of hosts and 
# and array of users on each host,
# pretty-prints a table showing usage of each hive.
output_table() {
  entries="$1"
  shift
  values=("${@}")
  bar="================================="
  echo "$bar"
  for ((i=0; i < $entries; i++)); do
    echo -e "| hive$((i+1))   \t| ${values[$i]}\t\t|"
  done
  echo "$bar"
}

rm -rf $PIPE_FILE
mkfifo $PIPE_FILE

for i in {1..28}; do
  check_host $i &
done

# After forking the subprocesses, have the master process
# repeatedly read from a pipe to collect responses
echo "Awaiting responses, this may take a moment..."
for i in {1..28}; do
  read -r report < $PIPE_FILE
  user_count=$(echo $report | cut -f1 -d':')
  host=$(echo $report | cut -f2 -d':')
  if [[ ! "$user_count" == "-1" ]]; then
    users[$host]=$user_count
    if [[ "$min_users" == "NONE" ]]; then
      min_users=$user_count
      min_users_host=$host
    elif [ "$user_count" -lt "$min_users" ]; then
      min_users=$user_count
      min_users_host=$host
    fi
  else
    users[$host]="Error"
  fi
done

# If no server could be reached
if [[ "$min_users" == "NONE" ]]; then
  echo "There was a problem and no hive server could be connected to."
  echo "Make sure that your SSH keys are setup properly; also, you may need to use the -i flag,"
  echo "and specify the path to your private key."
  exit 2
fi

# Pretty print the table of data collected
output_table 28 "${users[@]}"

# Clean up
rm -rf $PIPE_FILE

# Inform the user and login to the hive with the fewest users
echo "Least congested hive (fewest users) is hive${min_users_host} with ${min_users}. Logging in now..."
echo ""
ssh -i $ID_FILE ${HIVE_USER}@hive${min_users_host}.cs.berkeley.edu
